{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "modelname = 'src/model1.1.1_pan/'\n",
    "\n",
    "os.system('mkdir -p ./'+modelname)\n",
    "outputf = open(modelname+'/output.txt', 'w')\n",
    "\n",
    "outputf.write('OMP_NUM_THREADS = '+str(os.popen('echo $OMP_NUM_THREADS').read()) +'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "import keras, os, struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total  465 cosmologies\n",
      "Build up gridfile_dict... (for speed-up of load_grid()) \n",
      "\tmissing cosmology! om0.180_As2.040\n",
      "\tmissing cosmology! om0.180_As2.100\n",
      "\tmissing cosmology! om0.180_As2.120\n",
      "\tmissing cosmology! om0.180_As2.140\n",
      "\tmissing cosmology! om0.180_As2.200\n",
      "\tmissing cosmology! om0.180_As2.220\n",
      "\tmissing cosmology! om0.180_As2.260\n"
     ]
    }
   ],
   "source": [
    "#lsstr = \"ls /home/xiaodongli/data/colas/cola_multiverse/om_As/\"\n",
    "lsstr = \"ls /media/cosmo/Seagate/cola_multiverse/om_As/\"\n",
    "\n",
    "def cosmostr(om, As):\n",
    "    return 'om%.3f' % om + '_As%.3f' % As\n",
    "\n",
    "def snpfiles(cosmology, snpstr='c'):  #\n",
    "    return os.popen(lsstr + cosmology + \"*snap*\" + snpstr + \".*\").read().split()\n",
    "\n",
    "def gridfiles(cosmology, snpstr='c'):\n",
    "    return os.popen(lsstr + cosmology + \"*grid*\" + snpstr + \".*\").read().split()\n",
    "\n",
    "def mocklist():\n",
    "    files = os.popen(lsstr + \"om*.lua\").read().split('\\n')\n",
    "    # *代替多个字母,即列出所有符合条件的.lua文件:om...\n",
    "    cosmologies = []  # 宇宙学参数\n",
    "    mocks = {}  # 模拟测试\n",
    "    ifile = 0  # 有效文件\n",
    "    for nowfile in files:\n",
    "        # str[a:b]不存在时,返回'',不存在则忽略\n",
    "        nowstr = nowfile[-39:-10]\n",
    "        if nowstr == '':\n",
    "            continue\n",
    "        cosmologies.append(nowstr[0:15])\n",
    "        ifile += 1\n",
    "        try:\n",
    "            mocks[nowstr[0:15]] = {'om': float(nowstr[2:7]), 'As': float(nowstr[10:15]),\n",
    "                                   'sigma8': float(nowstr[23:29])}\n",
    "            # 添加随机数种子\n",
    "            ranseed = float(open(nowfile, 'r').readline().split()[2])  # 默认以所有空字符为分隔符,包括空格,\\n,\\t\n",
    "            mocks[nowstr[0:15]]['ranseed'] = int(ranseed)\n",
    "            # print(ranseed)\n",
    "        except:\n",
    "            pass\n",
    "    return cosmologies, files, mocks\n",
    "\n",
    "gridfile_dict = {}\n",
    "\n",
    "cosmologies, filenames, infos = mocklist()\n",
    "print('In total ', len(cosmologies), 'cosmologies')\n",
    "outputf.write('In total '+str(len(cosmologies))+'cosmologies\\n')\n",
    "\n",
    "print('Build up gridfile_dict... (for speed-up of load_grid()) ')\n",
    "outputf.write('Build up gridfile_dict... (for speed-up of load_grid()) \\n')\n",
    "for cosmology in cosmologies:\n",
    "    rlt = gridfiles(cosmology)\n",
    "    if rlt == []:\n",
    "        print ('\\tmissing cosmology!', cosmology)\n",
    "        outputf.write('\\tmissing cosmology!' +str(cosmology)+ '\\n')\n",
    "    else:\n",
    "        gridfile_dict[cosmology] = rlt[0]\n",
    "np.random.shuffle(cosmologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_grid(gridfile, snpstr='c', printinfo=False):  # 网格加载\n",
    "    #gridfile = os.popen(lsstr + cosmology+\"_sigma8_*grid*\" + snpstr + \".*\").read().split()[0]\n",
    "    #print('load in gridfile : ', gridfile, '...')\n",
    "    nowf = open(gridfile, 'rb')  # 以二进制形式读取文件\n",
    "    # struct:对python基本类型值与用python字符串格式表示的C struct类型间转化\n",
    "    size = struct.unpack('f' * 1, nowf.read(4 * 1))[0]\n",
    "    grid_nc = struct.unpack('i' * 1, nowf.read(4 * 1))[0]\n",
    "    data = struct.unpack('f' * grid_nc ** 3, nowf.read(4 * grid_nc ** 3))\n",
    "    if printinfo:\n",
    "        print('read in box size     \\n\\t', size)\n",
    "        print('read in num_grid      \\n\\t', grid_nc)\n",
    "        print('read in coarse grid \\n\\tsize    : ', len(data), '\\n\\texpect  : ', grid_nc ** 3)\n",
    "\n",
    "    nowf.close()\n",
    "    return np.array(data).reshape((grid_nc, grid_nc, grid_nc))\n",
    "\n",
    "def subcubes(A):\n",
    "    rlt = []\n",
    "    for row1 in [0, 32, 64, 96]:\n",
    "        for row2 in [0, 32, 64, 96]:\n",
    "            for row3 in [0, 32, 64, 96]:\n",
    "                rlt.append(A[row1:row1+32,row2:row2+32,row3:row3+32])\n",
    "    return rlt\n",
    "\n",
    "def data_augument(A):\n",
    "    rlt = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[37,\n",
       "  8,\n",
       "  66,\n",
       "  61,\n",
       "  42,\n",
       "  78,\n",
       "  94,\n",
       "  16,\n",
       "  30,\n",
       "  23,\n",
       "  88,\n",
       "  67,\n",
       "  87,\n",
       "  68,\n",
       "  2,\n",
       "  77,\n",
       "  75,\n",
       "  41,\n",
       "  29,\n",
       "  46,\n",
       "  11,\n",
       "  97,\n",
       "  0,\n",
       "  40,\n",
       "  32,\n",
       "  69,\n",
       "  31,\n",
       "  70,\n",
       "  57,\n",
       "  36,\n",
       "  56,\n",
       "  53,\n",
       "  35,\n",
       "  13,\n",
       "  15,\n",
       "  71,\n",
       "  54,\n",
       "  5,\n",
       "  63,\n",
       "  90,\n",
       "  33,\n",
       "  55,\n",
       "  93,\n",
       "  50,\n",
       "  65,\n",
       "  96,\n",
       "  21,\n",
       "  98,\n",
       "  25,\n",
       "  81,\n",
       "  17,\n",
       "  20,\n",
       "  9,\n",
       "  85,\n",
       "  91,\n",
       "  22,\n",
       "  92,\n",
       "  51,\n",
       "  76,\n",
       "  62,\n",
       "  1,\n",
       "  43,\n",
       "  60,\n",
       "  89,\n",
       "  7,\n",
       "  27,\n",
       "  6,\n",
       "  18,\n",
       "  95,\n",
       "  83,\n",
       "  79,\n",
       "  4,\n",
       "  82,\n",
       "  72,\n",
       "  86,\n",
       "  24,\n",
       "  64,\n",
       "  19,\n",
       "  84,\n",
       "  34,\n",
       "  44,\n",
       "  49,\n",
       "  39,\n",
       "  73,\n",
       "  48,\n",
       "  74,\n",
       "  52,\n",
       "  14,\n",
       "  80,\n",
       "  38,\n",
       "  26,\n",
       "  58,\n",
       "  47,\n",
       "  28,\n",
       "  99,\n",
       "  59,\n",
       "  3,\n",
       "  12,\n",
       "  10,\n",
       "  45],\n",
       " [],\n",
       " [37,\n",
       "  8,\n",
       "  66,\n",
       "  61,\n",
       "  42,\n",
       "  78,\n",
       "  94,\n",
       "  16,\n",
       "  30,\n",
       "  23,\n",
       "  88,\n",
       "  67,\n",
       "  87,\n",
       "  68,\n",
       "  2,\n",
       "  77,\n",
       "  75,\n",
       "  41,\n",
       "  29,\n",
       "  46,\n",
       "  11,\n",
       "  97,\n",
       "  0,\n",
       "  40,\n",
       "  32,\n",
       "  69,\n",
       "  31,\n",
       "  70,\n",
       "  57,\n",
       "  36,\n",
       "  56,\n",
       "  53,\n",
       "  35,\n",
       "  13,\n",
       "  15,\n",
       "  71,\n",
       "  54,\n",
       "  5,\n",
       "  63,\n",
       "  90,\n",
       "  33,\n",
       "  55,\n",
       "  93,\n",
       "  50,\n",
       "  65,\n",
       "  96,\n",
       "  21,\n",
       "  98,\n",
       "  25,\n",
       "  81,\n",
       "  17,\n",
       "  20,\n",
       "  9,\n",
       "  85,\n",
       "  91,\n",
       "  22,\n",
       "  92,\n",
       "  51,\n",
       "  76,\n",
       "  62,\n",
       "  1,\n",
       "  43,\n",
       "  60,\n",
       "  89,\n",
       "  7,\n",
       "  27,\n",
       "  6,\n",
       "  18,\n",
       "  95,\n",
       "  83,\n",
       "  79,\n",
       "  4,\n",
       "  82,\n",
       "  72,\n",
       "  86,\n",
       "  24,\n",
       "  64,\n",
       "  19,\n",
       "  84,\n",
       "  34,\n",
       "  44,\n",
       "  49,\n",
       "  39,\n",
       "  73,\n",
       "  48,\n",
       "  74,\n",
       "  52,\n",
       "  14,\n",
       "  80,\n",
       "  38,\n",
       "  26,\n",
       "  58,\n",
       "  47,\n",
       "  28,\n",
       "  99,\n",
       "  59,\n",
       "  3,\n",
       "  12,\n",
       "  10,\n",
       "  45],\n",
       " []]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### keras.models.save_model()\n",
    "rsync -avrP *.save xiaodongli@211.66.130.33:/home/xiaodongli/data/colas/cola_multiverse/AI/src/your_folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "batch_size = 6\n",
    "num_subcube = 64\n",
    "num_data_augument = 48\n",
    "\n",
    "x_test = np.zeros((int(test_size*batch_size)+1,32,32,32, 1))\n",
    "y_test = np.zeros((int(test_size*batch_size)+1, 2))\n",
    "\n",
    "\n",
    "###  xiaodong: 重新写了 load_grid 程序。。。之前有错误！！！！（好像只会 load 进来一个 om...)\n",
    "def train_generator():  # 必须无限循环yield数据,全部数据遍历后再重新遍历数据,为下一个epoch yield 数据\n",
    "    i = 0\n",
    "    while 1:\n",
    "        X = []\n",
    "        y = []\n",
    "        global x_train, x_test, y_test, y_train, test_size, batch_size\n",
    "        #print(' load in ', batch_size * i, 'to', batch_size * (i + 1), '... len(cosmologies)=',\n",
    "        #      len(cosmologies))\n",
    "        for cosmology in cosmologies[batch_size * i: batch_size * (i + 1)]:\n",
    "            try:\n",
    "                gridfile = gridfile_dict[cosmology]\n",
    "                griddata = load_grid(gridfile, 'c')\n",
    "                for subcube in subcubes(griddata):\n",
    "                    #for subsubcube in dataaug(subcube):\n",
    "                        #X.append(subsubcube)\n",
    "                        X.append(subcube)\n",
    "                        y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        x_train, x_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=test_size)\n",
    "        x_train = x_train.reshape(-1, 32, 32, 32, 1)\n",
    "        x_test = x_test.reshape(-1, 32, 32, 32, 1)\n",
    "        i += 1\n",
    "        yield x_train, y_train  # tuple 类型\n",
    "        # 15个批次后重新遍历数据,此循环即死循环\n",
    "        if i == 465//batch_size:\n",
    "            i = 0\n",
    "\n",
    "from keras import Sequential, layers\n",
    "from sklearn import model_selection, metrics\n",
    "\n",
    "\n",
    "def create_validate_sample(nsample, use_random=True, startid=None ):\n",
    "    cosmologies = list(gridfile_dict); ncosmo = len(cosmologies)\n",
    "    if use_random:\n",
    "        rows = [np.random.randint(0,ncosmo) for row in range(nsample)];\n",
    "        rows = list(set(rows))\n",
    "        while len(rows) < nsample:\n",
    "            rows = rows + [np.random.randint(0,ncosmo) for row in range(nsample - len(rows))];\n",
    "            rows = list(set(rows))\n",
    "    else:\n",
    "        rows = range(startid, startid+nsample)\n",
    "    x, y =[], []\n",
    "    for row in rows:\n",
    "        cosmology = cosmologies[row]\n",
    "        gridfile = gridfile_dict[cosmology]\n",
    "        griddata = load_grid(gridfile)\n",
    "        for subcube in subcubes(griddata):\n",
    "            x.append(subcube)\n",
    "            y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "    x = np.array(x); x = x.reshape(-1, 32, 32, 32, 1); y = np.array(y)\n",
    "    return x, y\n",
    "\n",
    "def plot_test(model, x, y, plot_avg_predict = True, fig=None, ax = None, plot_subpoints=False):\n",
    "    y_predict = model.predict(x); \n",
    "    \n",
    "    if fig == None or ax ==None:\n",
    "        fig, ax = plt.subplots(figsize=(14,6))\n",
    "    cs = range(len(y)); cs = cs / mean(cs)\n",
    "    ax.scatter(y[:,0], y[:,1], c='b', marker='*', label='input', s=200)\n",
    "    if plot_subpoints:\n",
    "        ax.scatter(y_predict[:,0], y_predict[:,1], c='g',  marker='p', s=50, label='outputs')\n",
    "    \n",
    "        \n",
    "    om_test, w_test = y[:,0], y[:,1]\n",
    "    om_predict, w_predict = y_predict[:,0], y_predict[:,1]\n",
    "    \n",
    "    if plot_avg_predict:\n",
    "        ax.scatter(mean(y_predict[:,0]), mean(y_predict[:,1]), marker='*', c='r', label='output_avg', s=200)\n",
    "        ax.plot([om_test[0], mean(y_predict[:,0])], [w_test[0], mean(y_predict[:,1])], lw=2, c='k', ls='--' )\n",
    "\n",
    "    \n",
    "    #for row in range(len(om_predict)):\n",
    "    #    ax.plot( [om_predict[row], om_test[row]], [w_predict[row], w_test[row]], lw=0.5, c='gray' )\n",
    "    ax.set_xlabel(r'$\\Omega_m$',fontsize=16); ax.set_ylabel(r'$\\sigma_8$',fontsize=16)\n",
    "    ax.legend()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cosmo/Software/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/cosmo/Software/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32, 1)     4         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 30, 30, 30, 32)    896       \n",
      "_________________________________________________________________\n",
      "average_pooling3d_1 (Average (None, 15, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 15, 15, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 13, 13, 13, 64)    55360     \n",
      "_________________________________________________________________\n",
      "average_pooling3d_2 (Average (None, 6, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 6, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 4, 4, 4, 128)      221312    \n",
      "_________________________________________________________________\n",
      "average_pooling3d_3 (Average (None, 2, 2, 2, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 2, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 1,590,470\n",
      "Trainable params: 1,590,276\n",
      "Non-trainable params: 194\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################################\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'modelname' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-dada61fec6b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'###############################################'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Begin training for '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m', current epochs = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'; max_epochs = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'###############################################'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moutputf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'###############################################\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modelname' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'y' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-425fd712de3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-0646e3ccf452>\u001b[0m in \u001b[0;36mplay\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'y' referenced before assignment"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.130736351013184\n"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "# import time\n",
    "# # start = time.time()\n",
    "# # Data Enhance method\n",
    "# size = 32\n",
    "# mat1= np.zeros((size, size, size))\n",
    "# # mat2= np.zeros((size, size, size))\n",
    "# # mat3= np.zeros((size, size, size))\n",
    "# # mat4= np.zeros((size, size, size))\n",
    "# # mat5= np.zeros((size, size, size))\n",
    "# # mat6= np.zeros((size, size, size))\n",
    "# # mat7 = np.zeros((size, size, size))\n",
    "\n",
    "# # def dataaug_sym(mat, size=32):\n",
    "# #     mat1 = np.zeros((size, size, size))\n",
    "# #     mat2 = np.zeros((size, size, size))\n",
    "# #     mat3 = np.zeros((size, size, size))\n",
    "# #     mat4 = np.zeros((size, size, size))\n",
    "# #     mat5 = np.zeros((size, size, size))\n",
    "# #     mat6 = np.zeros((size, size, size))\n",
    "# #     mat7 = np.zeros((size, size, size))\n",
    "# #     for i in range(size):\n",
    "# #         for j in range(size):\n",
    "# #             for k in range(size):\n",
    "# #                 mat1[i][j][k] = mat[size-1-i][j][k]\n",
    "# #                 mat2[i][j][k] = mat[size-1-i][size-1-j][k]\n",
    "# #                 mat3[i][j][k] = mat[size-1-i][size-1-j][size-1-k]\n",
    "# #                 mat4[i][j][k] = mat[size-1-i][j][size-1-k]  \n",
    "# #                 mat5[i][j][k] = mat[i][size-1-j][size-1-k]\n",
    "# #                 mat6[i][j][k] = mat[i][size-1-j][k]\n",
    "# #                 mat7[i][j][k] = mat[i][j][size-1-k]\n",
    "# #     return [mat, mat1, mat2, mat3, mat4, mat5, mat6, mat7]\n",
    "# # def dataaug(mat, size=32):\n",
    "# #     rlt = [] + dataaug_sym(mat) + dataaug_sym( mat.swapaxes(1, 2)) + \\\n",
    "# #         dataaug_sym(mat.swapaxes(0, 1))+ dataaug_sym(mat.swapaxes(1, 2)) +\\\n",
    "# #         dataaug_sym(mat.swapaxes(0, 1))+ dataaug_sym(mat.swapaxes(1, 2)\n",
    "# # pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X.pkl\", \"ab\")\n",
    "# # pickle_file2 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_y.pkl\", \"ab\")\n",
    "# def symmetric(mat):\n",
    "#     global size\n",
    "#     global mat1, mat2, mat3, mat4, mat5, mat6, mat7\n",
    "#     for i in range(size):\n",
    "#         for j in range(size):\n",
    "#             for k in range(size):\n",
    "#                 mat1[i][j][k] = mat[size-1-i][j][k]  # 12\n",
    "#                 mat2[i][j][k] = mat[size-1-i][size-1-j][k]  # 12\n",
    "#                 mat3[i][j][k] = mat[size-1-i][size-1-j][size-1-k]   # 1\n",
    "#                 mat4[i][j][k] = mat[size-1-i][j][size-1-k]   # 1\n",
    "#                 mat5[i][j][k] = mat[i][size-1-j][size-1-k]   # 1\n",
    "#                 mat6[i][j][k] = mat[i][size-1-j][k]   # 1\n",
    "#                 mat7[i][j][k] = mat[i][j][size-1-k]   # 1\n",
    "#     X.append(mat)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "#     X.append(mat1)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "#     X.append(mat2)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "#     X.append(mat3)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "#     X.append(mat4)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "#     X.append(mat5)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "#     X.append(mat6)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "#     X.append(mat7)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "# def dataEnhance(mat):\n",
    "#     symmetric(mat)\n",
    "#     mat = mat.swapaxes(1, 2)\n",
    "#     symmetric(mat)\n",
    "#     mat = mat.swapaxes(0, 1)\n",
    "#     symmetric(mat)\n",
    "#     mat = mat.swapaxes(1, 2)\n",
    "#     symmetric(mat)\n",
    "#     mat = mat.swapaxes(0, 1)\n",
    "#     symmetric(mat)\n",
    "#     mat = mat.swapaxes(1, 2)\n",
    "#     symmetric(mat)\n",
    "# # 读取数据\n",
    "# # for i in range(15):\n",
    "# #     X = []\n",
    "# #     y = []\n",
    "# #     #print(' load in ', batch_size * i, 'to', batch_size * (i + 1), '... len(cosmologies)=',\n",
    "# #     #      len(cosmologies))\n",
    "# #     for cosmology in cosmologies[31*i: 31*(i+1)]:\n",
    "# #         try:\n",
    "# #             gridfile = gridfile_dict[cosmol 'c']\n",
    "# #             for subcube in subcubes(griddata):\n",
    "# #                 dataEnhance(subcube)\n",
    "# #     #             X.append(subcube)\n",
    "# #     #             y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "# #         except:\n",
    "# #             pass\n",
    "# #     X = np.array(X)\n",
    "# #     y = np.array(y)\n",
    "# #     # x_train, x_test, y_train, y_test = model_slection.train_test_split(X, y, test_size=test_size)\n",
    "# #     # x_train = x_train.reshape(-1, 32, 32, 32, 1)\n",
    "# #     # x_test = x_test.reshape(-1, 32, 32, 32, 1)\n",
    "# #     pickle.dump(X, pickle_file1)\n",
    "# #     pickle.dump(y, pickle_file2)\n",
    "# #     end = time.time()\n",
    "# #     print(end-start)\n",
    "# # pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465\n",
      "1.0728099346160889\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "size = 32\n",
    "mat1= np.zeros((size, size, size))\n",
    "X = []\n",
    "y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][size-1-j][k]   # change\n",
    "#             X.append(mat1)\n",
    "#             #X.append(subcube)   （1，1）（1，2）（1，3）\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X2.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][size-1-j][size-1-k]    # change\n",
    "#             X.append(mat1)\n",
    "#             #X.append(subcube)   （1，1）（1，2）（1，3）（1，4）\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X4.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][j][size-1-k]    # change\n",
    "#             X.append(mat1)\n",
    "#             #X.append(subcube)   （1，1）（1，2）（1，3）（1，4）（1，5）\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X5.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][size-1-j][size-1-k]   # change\n",
    "#             X.append(mat1)\n",
    "#             #X.append(subcube)   （1，1）（1，2）（1，3）（1，4）（1，5）\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X6.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][size-1-j][k]   # change\n",
    "#             X.append(mat1)\n",
    "#             #X.append(subcube)   （1，1）（1，2）（1，3）（1，4）（1，5）\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X7.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][j][size-1-k]   # change\n",
    "#             X.append(mat1)\n",
    "#             #X.append(subcube)   （1，1）（1，2）（1，3）（1，4）（1，5）\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X8.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 32\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.swapaxes(1, 2) # change\n",
    "#             X.append(subcube)\n",
    "#             #X.append(subcube)   （1，1）\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X9.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.swapaxes(1, 2)\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][j][k]   # change\n",
    "#             X.append(mat1)\n",
    "#             #X.append(subcube)   （1，1）（1，2）\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X10.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.swapaxes(1, 2)\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][size-1-j][k]   # change\n",
    "#             X.append(mat1)\n",
    "#             #X.append(subcube)   （1，1）（1，2）\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X11.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.swapaxes(1, 2)\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][size-1-j][size-1-k]    # change\n",
    "#             X.append(mat1)\n",
    "#             #X.append(subcube)   （1，1）（1，2）\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X12.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.swapaxes(1, 2)\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][j][size-1-k]    # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X13.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.swapaxes(1, 2)\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][size-1-j][size-1-k]    # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X14.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.swapaxes(1, 2)\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][size-1-j][k]    # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X15.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.swapaxes(1, 2)\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][j][size-1-k]   # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X16.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((2,0,1)) # change\n",
    "#             X.append(subcube)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X17.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((2,0,1)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][j][k]   # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X18.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((2,0,1)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][size-1-j][k]   # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X19.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((2,0,1)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][size-1-j][size-1-k]   # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X20.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((2,0,1)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][j][size-1-k]    # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X21.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((2,0,1)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][size-1-j][size-1-k]    # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X22.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((2,0,1)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][size-1-j][k]     # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X23.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((2,0,1)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][j][size-1-k]     # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X24.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((2,1,0)) # change\n",
    "#             X.append(subcube)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X25.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((2,1,0)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][j][k]     # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X26.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((2,1,0)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][size-1-j][k]     # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X27.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((2,1,0)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][size-1-j][size-1-k]    # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X28.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((2,1,0)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][j][size-1-k]   # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X29.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((2,1,0)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][size-1-j][size-1-k]   # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X30.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "X = []\n",
    "y = []\n",
    "for cosmology in cosmologies[0: 465]:\n",
    "    try:\n",
    "        gridfile = gridfile_dict[cosmology]\n",
    "        griddata = load_grid(gridfile, 'c')\n",
    "        for subcube in subcubes(griddata):\n",
    "            subcube = subcube.transpose((2,1,0)) # change\n",
    "            for i in range(size):\n",
    "                for j in range(size):\n",
    "                    for k in range(size):\n",
    "                        mat1[i][j][k] = subcube[i][size-1-j][k]   # change\n",
    "            X.append(mat1)\n",
    "    except:\n",
    "        pass\n",
    "X = np.array(X)\n",
    "pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X31.pkl\", \"wb\")   # change\n",
    "pickle.dump(X, pickle_file1, protocol=4)\n",
    "pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((2,1,0)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][j][size-1-k]  # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X32.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,2,0)) # change\n",
    "#             X.append(subcube)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X33.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,2,0)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][j][k]  # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X34.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,2,0)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][size-1-j][k]  # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X35.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,2,0)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][size-1-j][size-1-k]   # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X36.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,2,0)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][j][size-1-k]   # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X37.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,2,0)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][size-1-j][size-1-k]  # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X38.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,2,0)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][size-1-j][k]  # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X39.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,2,0)) # change\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][j][size-1-k]  # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X40.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,0,2))\n",
    "#             X.append(subcube)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X41.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,0,2))\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][j][k] # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X42.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,0,2))\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][size-1-j][k] # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X43.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,0,2))\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][size-1-j][size-1-k] # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X44.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,0,2))\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[size-1-i][j][size-1-k]  # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X45.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,0,2))\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][size-1-j][size-1-k]  # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X46.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,0,2))\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][size-1-j][k]  # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X47.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "# X = []\n",
    "# y = []\n",
    "# for cosmology in cosmologies[0: 465]:\n",
    "#     try:\n",
    "#         gridfile = gridfile_dict[cosmology]\n",
    "#         griddata = load_grid(gridfile, 'c')\n",
    "#         for subcube in subcubes(griddata):\n",
    "#             subcube = subcube.transpose((1,0,2))\n",
    "#             for i in range(size):\n",
    "#                 for j in range(size):\n",
    "#                     for k in range(size):\n",
    "#                         mat1[i][j][k] = subcube[i][j][size-1-k] # change\n",
    "#             X.append(mat1)\n",
    "#     except:\n",
    "#         pass\n",
    "# X = np.array(X)\n",
    "# pickle_file1 = open(\"/media/cosmo/Seagate/DataEnhance/DataEnhance_X48.pkl\", \"wb\")   # change\n",
    "# pickle.dump(X, pickle_file1, protocol=4)\n",
    "# pickle_file1.close()\n",
    "###############################################################################################################\n",
    "# mat1[i][j][k] = mat[size-1-i][j][k]  # 123456\n",
    "# mat2[i][j][k] = mat[size-1-i][size-1-j][k]  # 123456\n",
    "# mat3[i][j][k] = mat[size-1-i][size-1-j][size-1-k]  # 123456\n",
    "# mat4[i][j][k] = mat[size-1-i][j][size-1-k]   # 123456\n",
    "# mat5[i][j][k] = mat[i][size-1-j][size-1-k]   # 123456\n",
    "# mat6[i][j][k] = mat[i][size-1-j][k]   # 123456\n",
    "# mat7[i][j][k] = mat[i][j][size-1-k]   # 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
