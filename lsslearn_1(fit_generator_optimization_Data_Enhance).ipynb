{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def symmetric(mat):\n",
    "#     size = 32\n",
    "#     mat1, mat2, mat3, mat4, mat5, mat6, mat7 = np.zeros((size, size, size)),np.zeros((size, size, size)),np.zeros((size, size, size)),np.zeros((size, size, size)),np.zeros((size, size, size)),np.zeros((size, size, size)),np.zeros((size, size, size))\n",
    "#     for i in range(size):\n",
    "#         for j in range(size):\n",
    "#             for k in range(size):\n",
    "#                 mat1[i][j][k] = mat[size-1-i][j][k]\n",
    "#                 mat2[i][j][k] = mat[size-1-i][size-1-j][k]\n",
    "#                 mat3[i][j][k] = mat[size-1-i][size-1-j][size-1-k]\n",
    "#                 mat4[i][j][k] = mat[size-1-i][j][size-1-k]\n",
    "#                 mat5[i][j][k] = mat[i][size-1-j][size-1-k]\n",
    "#                 mat6[i][j][k] = mat[i][size-1-j][k]\n",
    "#                 mat7[i][j][k] = mat[i][j][size-1-k]\n",
    "#     X.extend([mat, mat1, mat2, mat3, mat4, mat5, mat6, mat7])\n",
    "    \n",
    "# def dataEnhance(mat):\n",
    "#     size = 32\n",
    "#     mat1 = np.zeros((size, size, size))\n",
    "#     mat2 = np.zeros((size, size, size))\n",
    "#     mat3 = np.zeros((size, size, size))\n",
    "#     mat4 = np.zeros((size, size, size))\n",
    "#     mat5 = np.zeros((size, size, size))\n",
    "#     for i in range(size):\n",
    "#         for j in range(size):\n",
    "#             for k in range(size):\n",
    "#                 mat1[i][j][k] = mat[i][k][j]\n",
    "#                 mat2[i][j][k] = mat[k][i][j]\n",
    "#                 mat3[i][j][k] = mat[k][j][i]\n",
    "#                 mat4[i][j][k] = mat[j][i][k]\n",
    "#                 mat5[i][j][k] = mat[j][k][i]\n",
    "#     symmetric(mat)\n",
    "#     symmetric(mat1)\n",
    "#     symmetric(mat2)\n",
    "#     symmetric(mat3)\n",
    "#     symmetric(mat4)\n",
    "#     symmetric(mat5)\n",
    "\n",
    "# 不用运行，jupyter在后面模块中识别不了这段代码\n",
    "\n",
    "# import numpy as np\n",
    "# def symmetric(mat):\n",
    "#     size = 32\n",
    "#     mat1, mat2, mat3, mat4, mat5, mat6, mat7 = np.zeros((size, size, size)),np.zeros((size, size, size)),np.zeros((size, size, size)),np.zeros((size, size, size)),np.zeros((size, size, size)),np.zeros((size, size, size)),np.zeros((size, size, size))\n",
    "#     for i in range(size):\n",
    "#         for j in range(size):\n",
    "#             for k in range(size):\n",
    "#                 mat1[i][j][k] = mat[size-1-i][j][k]\n",
    "#                 mat2[i][j][k] = mat[size-1-i][size-1-j][k]\n",
    "#                 mat3[i][j][k] = mat[size-1-i][size-1-j][size-1-k]\n",
    "#                 mat4[i][j][k] = mat[size-1-i][j][size-1-k]\n",
    "#                 mat5[i][j][k] = mat[i][size-1-j][size-1-k]\n",
    "#                 mat6[i][j][k] = mat[i][size-1-j][k]\n",
    "#                 mat7[i][j][k] = mat[i][j][size-1-k]\n",
    "#     X.append(mat)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "#     X.append(mat1)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "#     X.append(mat2)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "#     X.append(mat3)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "#     X.append(mat4)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "#     X.append(mat5)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "#     X.append(mat6)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "#     X.append(mat7)\n",
    "#     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "# def dataEnhance(mat):\n",
    "#     size = 32\n",
    "#     symmetric(mat)\n",
    "#     mat = mat.swapaxes(1, 2)\n",
    "#     symmetric(mat)\n",
    "#     mat = mat.swapaxes(0, 1)\n",
    "#     symmetric(mat)\n",
    "#     mat = mat.swapaxes(1, 2)\n",
    "#     symmetric(mat)\n",
    "#     mat = mat.swapaxes(0, 1)\n",
    "#     symmetric(mat)\n",
    "#     mat = mat.swapaxes(1, 2)\n",
    "#     symmetric(mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以上是数据增强的测试代码，待检验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for some cosmologies data are missing...!!!??? we have to skip them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total  465 cosmologies\n",
      "Build up gridfile_dict... (for speed-up of load_grid()) \n",
      "\tmissing cosmology! om0.180_As2.040\n",
      "\tmissing cosmology! om0.180_As2.100\n",
      "\tmissing cosmology! om0.180_As2.120\n",
      "\tmissing cosmology! om0.180_As2.140\n",
      "\tmissing cosmology! om0.180_As2.200\n",
      "\tmissing cosmology! om0.180_As2.220\n",
      "\tmissing cosmology! om0.180_As2.260\n"
     ]
    }
   ],
   "source": [
    "#import os \n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import keras, os, pynbody, struct\n",
    "\n",
    "lsstr = \"ls /media/cosmo/Seagate/cola_multiverse/om_As/\"\n",
    "\n",
    "def cosmostr(om, As):\n",
    "    return 'om%.3f' % om + '_As%.3f' % As\n",
    "\n",
    "def snpfiles(cosmology, snpstr='c'):  #\n",
    "    return os.popen(lsstr + cosmology + \"*snap*\" + snpstr + \".*\").read().split()\n",
    "\n",
    "def gridfiles(cosmology, snpstr='c'):\n",
    "    return os.popen(lsstr + cosmology + \"*grid*\" + snpstr + \".*\").read().split()\n",
    "\n",
    "def mocklist():\n",
    "    files = os.popen(lsstr + \"om*.lua\").read().split('\\n')\n",
    "    # *代替多个字母,即列出所有符合条件的.lua文件:om...\n",
    "    cosmologies = []  # 宇宙学参数\n",
    "    mocks = {}  # 模拟测试\n",
    "    ifile = 0  # 有效文件\n",
    "    for nowfile in files:\n",
    "        # str[a:b]不存在时,返回'',不存在则忽略\n",
    "        nowstr = nowfile[-39:-10]\n",
    "        if nowstr == '':\n",
    "            continue\n",
    "        cosmologies.append(nowstr[0:15])\n",
    "        ifile += 1\n",
    "        try:\n",
    "            mocks[nowstr[0:15]] = {'om': float(nowstr[2:7]), 'As': float(nowstr[10:15]),\n",
    "                                   'sigma8': float(nowstr[23:29])}\n",
    "            # 添加随机数种子\n",
    "            ranseed = float(open(nowfile, 'r').readline().split()[2])  # 默认以所有空字符为分隔符,包括空格,\\n,\\t\n",
    "            mocks[nowstr[0:15]]['ranseed'] = int(ranseed)\n",
    "            # print(ranseed)\n",
    "        except:\n",
    "            pass\n",
    "    return cosmologies, files, mocks\n",
    "\n",
    "gridfile_dict = {}\n",
    "\n",
    "cosmologies, filenames, infos = mocklist()\n",
    "print('In total ', len(cosmologies), 'cosmologies')\n",
    "\n",
    "print('Build up gridfile_dict... (for speed-up of load_grid()) ')\n",
    "for cosmology in cosmologies:\n",
    "    rlt = gridfiles(cosmology)\n",
    "    if rlt == []:\n",
    "        print ('\\tmissing cosmology!', cosmology)\n",
    "    else:\n",
    "        gridfile_dict[cosmology] = rlt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_grid(gridfile, snpstr='c', printinfo=False):  # 网格加载\n",
    "    #gridfile = os.popen(lsstr + cosmology+\"_sigma8_*grid*\" + snpstr + \".*\").read().split()[0]\n",
    "    #print('load in gridfile : ', gridfile, '...')\n",
    "    nowf = open(gridfile, 'rb')  # 以二进制形式读取文件\n",
    "    # struct:对python基本类型值与用python字符串格式表示的C struct类型间转化\n",
    "    size = struct.unpack('f' * 1, nowf.read(4 * 1))[0]\n",
    "    grid_nc = struct.unpack('i' * 1, nowf.read(4 * 1))[0]\n",
    "    data = struct.unpack('f' * grid_nc ** 3, nowf.read(4 * grid_nc ** 3))\n",
    "    if printinfo:\n",
    "        print('read in box size     \\n\\t', size)\n",
    "        print('read in num_grid      \\n\\t', grid_nc)\n",
    "        print('read in coarse grid \\n\\tsize    : ', len(data), '\\n\\texpect  : ', grid_nc ** 3)\n",
    "    nowf.close()\n",
    "    return np.array(data).reshape((grid_nc, grid_nc, grid_nc))\n",
    "\n",
    "def subcubes(A):  # the X data\n",
    "    rlt = []\n",
    "    for row1 in [0, 32, 64]:\n",
    "        for row2 in [0, 32, 64]:\n",
    "            for row3 in [0, 32, 64]:\n",
    "                rlt.append(A[row1:row1+32,row2:row2+32,row3:row3+32])\n",
    "    return rlt\n",
    "\n",
    "def data_augument(A):\n",
    "    rlt = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lsstr = \"ls /media/minstrel/Seagate/cola_multiverse/om_As/\"\n",
    "# 初始化数据集,因函数定义中参数不可转为全局变量\n",
    "# 此过程受train_test_split的test_size参数的影响,则今后更改或维护程序应注意\n",
    "test_size = 0.3\n",
    "batch_size = 4  # size : 15 <= size < 31\n",
    "# 20:53-54s, 11:49s\n",
    "num_subcube = 64\n",
    "num_data_augument = 48\n",
    "\n",
    "x_test = np.zeros((int(test_size*batch_size)+1,32,32,32, 1))\n",
    "y_test = np.zeros((int(test_size*batch_size)+1, 2))\n",
    "# x_test = np.zeros((int(test_size*batch_size)+1,32,32,32, 1))\n",
    "# y_test = np.zeros((int(test_size*batch_size)+1, 2))\n",
    "\n",
    "\n",
    "def train_generator():  # 必须无限循环yield数据,全部数据遍历后再重新遍历数据,为下一个epoch yield 数据\n",
    "    def symmetric(mat):\n",
    "        size = 32\n",
    "        mat1, mat2, mat3, mat4, mat5, mat6, mat7 = np.zeros((size, size, size)),np.zeros((size, size, size)),np.zeros((size, size, size)),np.zeros((size, size, size)),np.zeros((size, size, size)),np.zeros((size, size, size)),np.zeros((size, size, size))\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                for k in range(size):\n",
    "                    mat1[i][j][k] = mat[size-1-i][j][k]\n",
    "                    mat2[i][j][k] = mat[size-1-i][size-1-j][k]\n",
    "                    mat3[i][j][k] = mat[size-1-i][size-1-j][size-1-k]\n",
    "                    mat4[i][j][k] = mat[size-1-i][j][size-1-k]\n",
    "                    mat5[i][j][k] = mat[i][size-1-j][size-1-k]\n",
    "                    mat6[i][j][k] = mat[i][size-1-j][k]\n",
    "                    mat7[i][j][k] = mat[i][j][size-1-k]\n",
    "        X.append(mat)\n",
    "        y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "        X.append(mat1)\n",
    "        y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "        X.append(mat2)\n",
    "        y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "        X.append(mat3)\n",
    "        y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "        X.append(mat4)\n",
    "        y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "        X.append(mat5)\n",
    "        y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "        X.append(mat6)\n",
    "        y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "        X.append(mat7)\n",
    "        y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "    def dataEnhance(mat):\n",
    "        size = 32\n",
    "        symmetric(mat)\n",
    "        mat = mat.swapaxes(1, 2)\n",
    "        symmetric(mat)\n",
    "        mat = mat.swapaxes(0, 1)\n",
    "        symmetric(mat)\n",
    "        mat = mat.swapaxes(1, 2)\n",
    "        symmetric(mat)\n",
    "        mat = mat.swapaxes(0, 1)\n",
    "        symmetric(mat)\n",
    "        mat = mat.swapaxes(1, 2)\n",
    "        symmetric(mat)\n",
    "    i = 0\n",
    "    while 1:\n",
    "        X = []\n",
    "        y = []\n",
    "        global x_test, y_test, test_size, batch_size\n",
    "        for cosmology in cosmologies[batch_size * i: batch_size * (i + 1)]:\n",
    "            try:\n",
    "                gridfile = gridfile_dict[cosmology]\n",
    "                griddata = load_grid(gridfile, 'c')\n",
    "                for subcube in subcubes(griddata):\n",
    "                    dataEnhance(subcube)   # X添加48个数据\n",
    "#                     X.append(subcube)\n",
    "#                     y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        x_train, x_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=test_size)\n",
    "        x_train = x_train.reshape(-1, 32, 32, 32, 1)\n",
    "        x_test = x_test.reshape(-1, 32, 32, 32, 1)\n",
    "        i += 1\n",
    "        yield x_train, y_train\n",
    "        # 15个批次后重新遍历数据,此循环即死循环\n",
    "        if i == 465//batch_size:\n",
    "            i = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3628,30,30,30,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv3d_16/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss_5/mul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-95de0ce68590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Software/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3628,30,30,30,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv3d_16/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss_5/mul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential, layers\n",
    "from sklearn import model_selection, metrics\n",
    "\n",
    "model1 = keras.Sequential([\n",
    "    layers.BatchNormalization( input_shape=(32, 32, 32, 1)),\n",
    "    layers.Conv3D(32, (3, 3, 3), activation='relu'),\n",
    "    layers.AveragePooling3D(pool_size=(2, 2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv3D(64, (3, 3, 3), activation='relu'),\n",
    "    layers.AveragePooling3D(pool_size=(2, 2, 2)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv3D(128, (3, 3, 3), activation='relu'),\n",
    "    layers.AveragePooling3D(pool_size=(2, 2, 2)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(2, ),\n",
    "])\n",
    "model1.compile(optimizer=keras.optimizers.Adadelta(), loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error'])\n",
    "\n",
    "\n",
    "\n",
    "# *************************************************************************************************\n",
    "model1.fit_generator(train_generator(),\n",
    "                    steps_per_epoch=465//batch_size,\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from keras import Sequential, layers\n",
    "from sklearn import model_selection, metrics\n",
    "\n",
    "start = time.clock()\n",
    "test_size = 0.3\n",
    "batch_size = 15  # size : 15 <= size < 31\n",
    "num_subcube = 64\n",
    "num_data_augument = 48\n",
    "\n",
    "x_test = np.zeros((int(test_size*batch_size)+1,32,32,32, 1))\n",
    "# print(\"first dimension\", int(test_size*batch_size*48*27)+1)\n",
    "y_test = np.zeros((int(test_size*batch_size)+1, 2))\n",
    "X = []\n",
    "y = []\n",
    "for cosmology in cosmologies[1:2]:\n",
    "    try:\n",
    "        gridfile = gridfile_dict[cosmology]\n",
    "        griddata = load_grid(gridfile, 'c')\n",
    "        for subcube in subcubes(griddata):\n",
    "#             X.append(subcube)\n",
    "#             y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "            dataEnhance(subcube)\n",
    "            for j in range(48):\n",
    "                        y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "            # print(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]).shape)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=test_size)\n",
    "x_train = x_train.reshape(-1, 32, 32, 32, 1)\n",
    "x_test = x_test.reshape(-1, 32, 32, 32, 1)\n",
    "print(\"yTest:\",y_test.shape)\n",
    "print(\"xTest:\",x_test.shape)\n",
    "print(\"xTrain:\",x_train.shape)\n",
    "print(\"yTrain:\",y_train.shape)\n",
    "print(int(test_size*batch_size)+1)\n",
    "elapsed = (time.clock() - start)\n",
    "print(\"Time used:\",elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validate_sample(nsample, use_random=True, startid=None ):\n",
    "    cosmologies = list(gridfile_dict); ncosmo = len(cosmologies)\n",
    "    if use_random:\n",
    "        rows = [np.random.randint(0,ncosmo) for row in range(nsample)];\n",
    "        rows = list(set(rows))\n",
    "        while len(rows) < nsample:\n",
    "            rows = rows + [np.random.randint(0,ncosmo) for row in range(nsample - len(rows))];\n",
    "            rows = list(set(rows))\n",
    "    else:\n",
    "        rows = range(startid, startid+nsample)\n",
    "    x, y =[], []\n",
    "    for row in rows:\n",
    "        cosmology = cosmologies[row]\n",
    "        gridfile = gridfile_dict[cosmology]\n",
    "        griddata = load_grid(gridfile)\n",
    "        for subcube in subcubes(griddata):\n",
    "            x.append(subcube)\n",
    "            y.append(np.array([infos[cosmology]['om'], infos[cosmology]['sigma8']]))\n",
    "    x = np.array(x); x = x.reshape(-1, 32, 32, 32, 1); y = np.array(y)\n",
    "    return x, y\n",
    "\n",
    "def plot_test(model, x, y, plot_avg_predict = True, fig=None, ax = None, plot_subpoints=False):\n",
    "    y_predict = model.predict(x); \n",
    "    \n",
    "    if fig == None or ax ==None:\n",
    "        fig, ax = subplots(figsize=(14,6))\n",
    "    cs = range(len(y)); cs = cs / mean(cs)\n",
    "    ax.scatter(y[:,0], y[:,1], c='b', marker='*', label='input', s=200)\n",
    "    if plot_subpoints:\n",
    "        ax.scatter(y_predict[:,0], y_predict[:,1], c='g',  marker='p', s=50, label='outputs')\n",
    "    \n",
    "        \n",
    "    om_test, w_test = y[:,0], y[:,1]\n",
    "    om_predict, w_predict = y_predict[:,0], y_predict[:,1]\n",
    "    \n",
    "    if plot_avg_predict:\n",
    "        ax.scatter(mean(y_predict[:,0]), mean(y_predict[:,1]), marker='*', c='r', label='output_avg', s=200)\n",
    "        ax.plot([om_test[0], mean(y_predict[:,0])], [w_test[0], mean(y_predict[:,1])], lw=2, c='k', ls='--' )\n",
    "\n",
    "    \n",
    "    #for row in range(len(om_predict)):\n",
    "    #    ax.plot( [om_predict[row], om_test[row]], [w_predict[row], w_test[row]], lw=0.5, c='gray' )\n",
    "    ax.set_xlabel(r'$\\Omega_m$',fontsize=16); ax.set_ylabel(r'$w$',fontsize=16)\n",
    "    ax.legend()   \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### model1, 10 epochs: Don't run it! (参数已改不可恢复）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = None, None\n",
    "for row in range(10):\n",
    "    x_test, y_test = create_validate_sample(1, use_random=True, startid=row)\n",
    "    fig, ax = plot_test(model1, x_test, y_test, fig=fig, ax=ax)\n",
    "ax.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 50 epochs`5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = None, None\n",
    "for row in range(10):\n",
    "    x_test, y_test = create_validate_sample(1, use_random=True, startid=row)\n",
    "    fig, ax = plot_test(model1, x_test, y_test, fig=fig, ax=ax)\n",
    "ax.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### model2, 10 epochs: Don't run it! (参数已改不可恢复）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = None, None\n",
    "for row in range(10):\n",
    "    x_test, y_test = create_validate_sample(1, use_random=True, startid=row)\n",
    "    fig, ax = plot_test(model2, x_test, y_test, fig=fig, ax=ax)\n",
    "ax.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = None, None\n",
    "for row in range(10):\n",
    "    x_test, y_test = create_validate_sample(1, use_random=True, startid=row)\n",
    "    fig, ax = plot_test(model2, x_test, y_test, fig=fig, ax=ax)\n",
    "ax.grid(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
